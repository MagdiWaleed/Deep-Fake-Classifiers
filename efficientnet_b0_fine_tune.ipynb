{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-29T00:27:24.130165Z",
          "iopub.status.busy": "2024-12-29T00:27:24.129868Z",
          "iopub.status.idle": "2024-12-29T00:27:24.134887Z",
          "shell.execute_reply": "2024-12-29T00:27:24.134001Z",
          "shell.execute_reply.started": "2024-12-29T00:27:24.130142Z"
        },
        "id": "JPpn4PyW625u",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import shutil\n",
        "from copy import deepcopy\n",
        "from sklearn.model_selection import KFold\n",
        "from torch.utils.data import Subset,Dataset,DataLoader\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from torchvision import models\n",
        "from torchvision.models import Inception_V3_Weights\n",
        "import kagglehub\n",
        "\n",
        "\n",
        "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-29T00:27:24.147107Z",
          "iopub.status.busy": "2024-12-29T00:27:24.146882Z",
          "iopub.status.idle": "2024-12-29T00:27:24.151129Z",
          "shell.execute_reply": "2024-12-29T00:27:24.150387Z",
          "shell.execute_reply.started": "2024-12-29T00:27:24.147087Z"
        },
        "id": "tl7u0MwUB0WK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "number_videos = 200\n",
        "number_frames = 5\n",
        "batch_size = 0\n",
        "video_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-29T00:27:24.165937Z",
          "iopub.status.busy": "2024-12-29T00:27:24.165725Z",
          "iopub.status.idle": "2024-12-29T00:27:24.170283Z",
          "shell.execute_reply": "2024-12-29T00:27:24.169465Z",
          "shell.execute_reply.started": "2024-12-29T00:27:24.165918Z"
        },
        "id": "rrsrDcqa625v",
        "outputId": "c3eb3e0e-63ca-4333-9532-040d75dfc74a",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.5), please consider upgrading to the latest version (0.3.6).\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/hhalalwi/deepfake-face-mask-dataset-dffmd?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.29G/9.29G [02:14<00:00, 74.3MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/hhalalwi/deepfake-face-mask-dataset-dffmd/versions/1\n"
          ]
        }
      ],
      "source": [
        "path = kagglehub.dataset_download(\"hhalalwi/deepfake-face-mask-dataset-dffmd\")\n",
        "# path = \"/kaggle/input/deepfake-face-mask-dataset-dffmd\"\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-29T00:27:24.180263Z",
          "iopub.status.busy": "2024-12-29T00:27:24.180049Z",
          "iopub.status.idle": "2024-12-29T00:27:24.184861Z",
          "shell.execute_reply": "2024-12-29T00:27:24.183960Z",
          "shell.execute_reply.started": "2024-12-29T00:27:24.180245Z"
        },
        "id": "vppTkLk4M5TB",
        "outputId": "aed7d26e-5cd3-4461-d677-9e7186aecb1f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda:0\")\n",
        "  print(\"GPU\")\n",
        "else:\n",
        "  device = torch.device(\"cpu\")\n",
        "  print(\"CPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-29T00:27:24.186141Z",
          "iopub.status.busy": "2024-12-29T00:27:24.185893Z",
          "iopub.status.idle": "2024-12-29T00:27:24.214516Z",
          "shell.execute_reply": "2024-12-29T00:27:24.213796Z",
          "shell.execute_reply.started": "2024-12-29T00:27:24.186111Z"
        },
        "id": "2slSA0LH7Obt",
        "outputId": "bd6596a1-e47d-4ac9-9fd9-7a2d1603d87a",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1836"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = []\n",
        "\n",
        "for folder in os.listdir(path):\n",
        "  if folder == \"Fake\" or folder == \"Real\":\n",
        "    for file in os.listdir(os.path.join(path,folder,folder)):\n",
        "      if folder == \"Fake\":\n",
        "        data.append([os.path.join(path,folder,folder,file),0])\n",
        "      else:\n",
        "        data.append([os.path.join(path,folder,folder,file),1])\n",
        "data = np.array(data)\n",
        "np.random.shuffle(data)\n",
        "len(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-29T00:27:24.216086Z",
          "iopub.status.busy": "2024-12-29T00:27:24.215805Z",
          "iopub.status.idle": "2024-12-29T00:27:24.223147Z",
          "shell.execute_reply": "2024-12-29T00:27:24.222184Z",
          "shell.execute_reply.started": "2024-12-29T00:27:24.216066Z"
        },
        "id": "46XsV3Tc9eXL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class VideoDataset(Dataset):\n",
        "    def __init__(self,data,number_frames):\n",
        "        self.data = []\n",
        "        self.labels = []\n",
        "        for i in data:\n",
        "            self.data.append(i[0])\n",
        "            self.labels.append(i[1])\n",
        "        self.number_frames = number_frames\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "    def __getitem__(self, idx):\n",
        "        frames = self.get_frames(self.data[idx])\n",
        "        return np.array(frames),int(self.labels[idx])\n",
        "\n",
        "    def get_frames(self, video_path):\n",
        "        cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "        total_frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        indices = np.linspace(0, total_frame_count - 1, self.number_frames, dtype=int)\n",
        "        frames = []\n",
        "\n",
        "        for index in indices:\n",
        "            cap.set(cv2.CAP_PROP_POS_FRAMES, index)\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            while not ret and index < total_frame_count - 1:\n",
        "                index += 1\n",
        "                cap.set(cv2.CAP_PROP_POS_FRAMES, index)\n",
        "                ret, frame = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            frame = cv2.resize(frame, (video_size, video_size))\n",
        "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            frames.append(frame)\n",
        "\n",
        "        cap.release()\n",
        "\n",
        "        if frames:\n",
        "            while len(frames) < self.number_frames:\n",
        "                frames.append(frames[-1].copy())\n",
        "        else:\n",
        "            raise ValueError(\"No frames were successfully extracted from the video.\")\n",
        "\n",
        "        return frames\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-12-29T00:27:24.224680Z",
          "iopub.status.busy": "2024-12-29T00:27:24.224393Z",
          "iopub.status.idle": "2024-12-29T00:27:24.240467Z",
          "shell.execute_reply": "2024-12-29T00:27:24.239599Z",
          "shell.execute_reply.started": "2024-12-29T00:27:24.224651Z"
        },
        "id": "-hUzBKftG1KH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def get_data(data,number_frames,number_videos=0):\n",
        "    if number_videos == 0:\n",
        "      vidoes_dataset = VideoDataset(data,number_frames)\n",
        "      return vidoes_dataset\n",
        "    else:\n",
        "      data = data[:number_videos]\n",
        "      vidoes_dataset = VideoDataset(data,number_frames)\n",
        "      data_frames = []\n",
        "      labels = []\n",
        "\n",
        "      for i in tqdm(range(len(vidoes_dataset))):\n",
        "        frames,label = vidoes_dataset[i]\n",
        "        data_frames.append(frames)\n",
        "        labels.append(int(label))\n",
        "\n",
        "      data_frames = np.array(data_frames)\n",
        "      print(data_frames.shape)\n",
        "      return (data_frames,labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-12-29T00:27:24.241471Z",
          "iopub.status.busy": "2024-12-29T00:27:24.241208Z"
        },
        "id": "q9efBg_-3N50",
        "outputId": "543a7122-3bd5-424e-a170-f5b9fa003a35",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 200/200 [03:41<00:00,  1.11s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200, 5, 256, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "dataset = get_data(data,number_frames,number_videos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4tq_NjaH46L",
        "outputId": "a3f0985c-4118-4e20-9bec-66c1aac95430",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|██████████| 20.5M/20.5M [00:00<00:00, 85.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "213\n"
          ]
        }
      ],
      "source": [
        "# image = torch.tensor(np.random.normal(5,10,size=(40,3,224,224))).float()\n",
        "# print(image.shape)\n",
        "resnet50 = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "model = nn.Sequential(\n",
        "    resnet50.features\n",
        ")\n",
        "\n",
        "# predicted = model(image)\n",
        "# print(predicted.size())\n",
        "# list(model.children())[-2:]\n",
        "# list(model.named_parameters())\n",
        "print(len(list(resnet50.parameters())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5D7JycEc625y",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        efficientnet_b0 = models.efficientnet_b0(weights=models.EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            efficientnet_b0.features\n",
        "        )\n",
        "\n",
        "        t=0\n",
        "        for layer in efficientnet_b0.parameters():\n",
        "            t+=1\n",
        "\n",
        "        for i,layer in enumerate(efficientnet_b0.parameters()):\n",
        "            layer.requires_grad = False\n",
        "            if i== (t-4) or i== (t-5):\n",
        "              layer.requires_grad = True\n",
        "        self.maxPool = nn.MaxPool2d(7)\n",
        "        self.lstm = nn.LSTM(1280, 512,2 , batch_first=True)\n",
        "\n",
        "\n",
        "        self.linear1 = nn.Linear(512,120)\n",
        "        self.linear2 = nn.Linear(120,84)\n",
        "        self.linear3 = nn.Linear(84,1)\n",
        "\n",
        "    def forward(self,x):\n",
        "         batch_size, num_frames, channels, height, width = x.size()\n",
        "         x = x.view(batch_size * num_frames, channels, height, width)\n",
        "         # print(f\"Shape of x before passing to model: {x.shape}\")\n",
        "         x = self.model(x)\n",
        "         x = self.maxPool(x)\n",
        "         # print(x.size())\n",
        "         x = x.reshape(batch_size, -1)\n",
        "         x = x.reshape(batch_size,num_frames,-1)\n",
        "\n",
        "\n",
        "         lstm_out, _= self.lstm(x)\n",
        "\n",
        "\n",
        "         x = lstm_out[:,-1,:]\n",
        "\n",
        "\n",
        "         x = x.reshape(batch_size, -1)\n",
        "\n",
        "         x = F.relu(self.linear1(x))\n",
        "\n",
        "         x = F.relu(self.linear2(x))\n",
        "\n",
        "         x = F.sigmoid(self.linear3(x))\n",
        "\n",
        "\n",
        "         return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VnkM9cZc625z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def train(data,epoch ,model,optimizer,loss_fun):\n",
        "\n",
        "    total_loss = []\n",
        "    model.train()\n",
        "    for ep in tqdm(range(epoch)):\n",
        "      if number_videos !=0:\n",
        "        optimizer.zero_grad()\n",
        "        x = torch.tensor(data[0]).to(device)\n",
        "\n",
        "        x = x.permute(0,1, 4, 2, 3) # batch_size, num_frames, channels, height, width\n",
        "        x = x.float()\n",
        "\n",
        "        target = torch.tensor(data[1]).to(device)\n",
        "        target = target.float()\n",
        "        target = target.unsqueeze(-1)\n",
        "        outputs = model(x)\n",
        "        loss = loss_fun(outputs,target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "      else:\n",
        "        for i, (x, target) in enumerate(data):\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            target = torch.tensor(target)\n",
        "            target = target.float()\n",
        "            x = torch.tensor(x)\n",
        "\n",
        "            x = x.permute(0,1, 4, 2, 3) # batch_size, num_frames, channels, height, width\n",
        "            x = x.float()\n",
        "\n",
        "            target = target.to(device)\n",
        "            x= x.to(device)\n",
        "\n",
        "            outputs = model(x)\n",
        "\n",
        "            loss = loss_fun(outputs,target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "      total_loss.append(float(loss))\n",
        "\n",
        "\n",
        "    return total_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XcM6KSsBJ8dD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class GreyWolfOA:\n",
        "    def __init__(self, n=5,i=100):\n",
        "        self.population_size = n\n",
        "        self.iterations = i\n",
        "    def fittness(self, population,is_fittness_calculated,previous_fittness_values):\n",
        "        population = np.array(population)\n",
        "        values = []\n",
        "        i=0\n",
        "        print(\"fittness: \")\n",
        "        for index,sample in enumerate(population):\n",
        "          if is_fittness_calculated[index]:\n",
        "            values.append(previous_fittness_values[index])\n",
        "            continue\n",
        "          elif population[index]<0:\n",
        "            values.append(10000000)\n",
        "            continue\n",
        "          else:\n",
        "            print(\"lr: \",population[index])\n",
        "            model = CNN().to(self.device)\n",
        "            optimizer = torch.optim.Adam(model.parameters(),lr= sample)\n",
        "            loss_fun = nn.BCELoss()\n",
        "            history = train(self.data,10,model,optimizer,loss_fun)\n",
        "            # print(np.array(history[\"loss\"][-5:]).mean())\n",
        "            values.append(np.array(history[-5:]).mean())\n",
        "            i+=1\n",
        "            is_fittness_calculated[index] = True\n",
        "        return values , is_fittness_calculated\n",
        "\n",
        "    def calc_singleX(self,a,sample_i, wolf):#wolf = (alpha,beta,gamma)\n",
        "        random1,random2 = np.random.uniform(0.00001,0.001),np.random.uniform(0.00001,0.001)\n",
        "        A = (2*a* random1) - a\n",
        "        B = 2* random2\n",
        "        C = np.abs(B* wolf - sample_i)\n",
        "        x = wolf - A*C\n",
        "        return x\n",
        "\n",
        "    def fit(self,data,device):\n",
        "        self.data = data\n",
        "        self.device = device\n",
        "\n",
        "        population = np.random.uniform(0.00001,0.001,size=self.population_size)\n",
        "        is_fittness_calculated= [False for _ in range(self.population_size)]\n",
        "        history = []\n",
        "        previous_fittness_values = []\n",
        "        for i in range(self.iterations):\n",
        "\n",
        "            fitness_values,is_fittness_calculated = self.fittness(population,is_fittness_calculated,previous_fittness_values)\n",
        "            indecies = np.argsort(fitness_values)\n",
        "\n",
        "            alpha = population[indecies[0]]\n",
        "            beta = population[indecies[1]]\n",
        "            gamma = population[indecies[2]]\n",
        "            a = 2 *(1-(i /self.iterations))**30\n",
        "\n",
        "            for sample in range(self.population_size):\n",
        "                x1 = self.calc_singleX(a,sample,alpha)\n",
        "                x2 = self.calc_singleX(a,sample,beta)\n",
        "                x3 = self.calc_singleX(a,sample,gamma)\n",
        "\n",
        "\n",
        "                new_x = (x1+x2+x3)/3\n",
        "                new_fittness,_= self.fittness([new_x],[False],[0])\n",
        "                if fitness_values[sample] > new_fittness[0]:\n",
        "                    population[sample] = new_x\n",
        "                    fitness_values[sample]= new_fittness[0]\n",
        "                    is_fittness_calculated[sample]=True\n",
        "\n",
        "            previous_fittness_values= deepcopy(fitness_values)\n",
        "\n",
        "            indecies = np.argsort(fitness_values)\n",
        "            history.append([population[indecies[0]],fitness_values[indecies[0]]])\n",
        "            print(\"-----------alpha is: \",population[indecies[0]],\"loss: \",fitness_values[indecies[0]])\n",
        "            print('-----------------------------------------------------------')\n",
        "            print(f'Iteration {i+1}population: {population}')\n",
        "        return population[indecies[0]],history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jnrEGW_B625z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# greywolf = GreyWolfOA(5,10)\n",
        "# alpha , history = greywolf.fit(dataset,device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "mEhw26aMzra5",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model, loss_fun,data_loader):\n",
        "  model.eval()\n",
        "  data_loss = 0.0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    if number_videos !=0:\n",
        "        train,labels = data_loader\n",
        "        x, y = torch.tensor(train).to(device), torch.tensor(labels).to(device)\n",
        "        x = x.permute(0,1, 4, 2, 3) # batch_size, num_frames, channels, height, width\n",
        "        x = x.float()\n",
        "\n",
        "        outputs = model(x)\n",
        "        y = y.float()\n",
        "        y = y.unsqueeze(-1)\n",
        "\n",
        "        loss = loss_fun(outputs, y)\n",
        "        data_loss += loss.item()\n",
        "        for t in range(len(outputs)):\n",
        "          if outputs[t] >= 0.5 and y[t]==1:\n",
        "            correct+= 1\n",
        "            total+=1\n",
        "          elif outputs[t] < 0.5 and y[t]==0:\n",
        "            correct += 1\n",
        "            total+=1\n",
        "          else:\n",
        "            total+=1\n",
        "    else:\n",
        "      for i,(x, y) in enumerate(data_loader):\n",
        "          x, y = x.clone().detach().to(device), y.clone().detach().to(device)\n",
        "          x = x.permute(0,1, 4, 2, 3) # batch_size, num_frames, channels, height, width\n",
        "          x = x.float()\n",
        "          outputs = model(x)\n",
        "          y = y.float()\n",
        "          y = y.unsqueeze(-1)\n",
        "\n",
        "          loss = loss_fun(outputs, y)\n",
        "          data_loss += loss.item()\n",
        "          for t in range(len(outputs)):\n",
        "            if outputs[t] >= 0.5 and y[t]==1:\n",
        "              correct+= 1\n",
        "              total+=1\n",
        "            elif outputs[t] < 0.5 and y[t]==0:\n",
        "              correct += 1\n",
        "              total+=1\n",
        "            else:\n",
        "              total+=1\n",
        "          predicted = np.array(outputs.cpu().numpy()>=0.5).astype(int)\n",
        "          correct += (predicted == y.cpu().numpy()).sum().item()\n",
        "          total += y.size(0)\n",
        "\n",
        "\n",
        "  data_loss /= len(data_loader)\n",
        "  val_accuracy = correct / total\n",
        "  return data_loss, val_accuracy\n",
        "\n",
        "def train_cross_validation(data,epoch):\n",
        "\n",
        "    k_folds = 3\n",
        "    kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
        "\n",
        "    fold_results=[]\n",
        "    models_details=[]\n",
        "\n",
        "    if number_videos !=0:\n",
        "      splited_data = data[0]\n",
        "    else:\n",
        "      splited_data = data\n",
        "\n",
        "    for fold_number,(train_idx,val_idx) in enumerate(kf.split(splited_data)):\n",
        "\n",
        "      if number_videos != 0:\n",
        "        train_videos = np.array(data[0])[train_idx]\n",
        "        train_labels = np.array(data[1])[train_idx]\n",
        "\n",
        "        val_videos = np.array(data[0])[val_idx]\n",
        "        val_labels = np.array(data[1])[val_idx]\n",
        "\n",
        "      else:\n",
        "        train_subset = Subset(splited_data, train_idx)\n",
        "        val_subset = Subset(splited_data, val_idx)\n",
        "\n",
        "        train_loader = DataLoader(train_subset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_subset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "      model = CNN().to(device)\n",
        "      optimizer = torch.optim.Adam(model.parameters(),lr=0.00275933131073064     )\n",
        "      loss_fun = nn.BCELoss()\n",
        "\n",
        "      print(f\"fold {fold_number+1}/3: ----------------------------- \")\n",
        "      total_loss = []\n",
        "      model.train()\n",
        "      # for ep in range(epoch):\n",
        "      if number_videos !=0:\n",
        "        for ep in range(epoch):\n",
        "          optimizer.zero_grad()\n",
        "          x = torch.tensor(train_videos).to(device)\n",
        "\n",
        "          x = x.permute(0,1, 4, 2, 3) # batch_size, num_frames, channels, height, width\n",
        "          x = x.float()\n",
        "\n",
        "          target = torch.tensor(train_labels).to(device)\n",
        "          target = target.float()\n",
        "          target = target.unsqueeze(-1)\n",
        "          outputs = model(x)\n",
        "          loss = loss_fun(outputs,target)\n",
        "          loss.backward()\n",
        "          optimizer.step()\n",
        "          print(f\"\\rEpoch {ep+1}, loss: {loss.item():.8f}\",end=\"\")\n",
        "          total_loss.append(float(loss))\n",
        "\n",
        "      else:\n",
        "          for i, (x, target) in enumerate(train_loader):\n",
        "          # target = target.clone().detach().requires_grad_(True)\n",
        "              target = target.clone().detach()\n",
        "              target = target.float()\n",
        "\n",
        "              x = x.permute(0,1, 4, 2, 3) # batch_size, num_frames, channels, height, width\n",
        "              x = x.float()\n",
        "              target = target.to(device).unsqueeze(-1)\n",
        "              x= x.to(device)\n",
        "              for ep in range(epoch):\n",
        "                  optimizer.zero_grad()\n",
        "\n",
        "\n",
        "                  outputs = model(x)\n",
        "\n",
        "                  loss = loss_fun(outputs,target)\n",
        "                  loss.backward()\n",
        "                  optimizer.step()\n",
        "                  print(f\"\\rEpoch {ep+1}, loss: {loss.item():.8f}, [{i}/{len(train_loader)}]\",end=\"\")\n",
        "                  total_loss.append(float(loss))\n",
        "\n",
        "\n",
        "      if number_videos != 0:\n",
        "        loss,accuracy = evaluate_model(model,loss_fun,(val_videos,val_labels))\n",
        "        y_true = val_labels\n",
        "        y_predict = predict(model,val_videos)\n",
        "      else:\n",
        "        # loss,accuracy = evaluate_model(model,loss_fun,val_loader)\n",
        "        y_true,y_predict = predict(model,val_loader)\n",
        "      models_details.append(\n",
        "      {\n",
        "      \"loss\":total_loss,\n",
        "      # \"accuracy\":accuracy,\n",
        "      #  \"precision\":precision_score(y_true,y_predict),\n",
        "      # \"recall\":recall_score(y_true,y_predict),\n",
        "      # \"f1\":f1_score(y_true,y_predict),\n",
        "      \"classification\": classification_report(y_true,y_predict,zero_division=0)\n",
        "      }\n",
        "      )\n",
        "      print(classification_report(y_true,y_predict,zero_division=0))\n",
        "      print()\n",
        "      print(f\"Fold {fold_number + 1}, loss: {float(loss)}\")\n",
        "      print(\"-----------------------------------------------------------------------------------------------------\")\n",
        "      # fold_results.append((val_loss, accuracy))\n",
        "      # if fold_number==0:\n",
        "      #   break\n",
        "\n",
        "    return models_details\n",
        "\n",
        "def predict(model,data):\n",
        "\n",
        "     model.eval()\n",
        "     with torch.no_grad():\n",
        "        if number_videos !=0:\n",
        "          x = torch.tensor(data).to(device)\n",
        "\n",
        "          x = x.permute(0,1, 4, 2, 3) # batch_size, num_frames, channels, height, width\n",
        "          x = x.float()\n",
        "\n",
        "          outputs = model(x)\n",
        "          outputs = np.array(outputs.cpu().numpy()>=0.5).astype(int)\n",
        "          return outputs.squeeze()\n",
        "        else:\n",
        "          actual = []\n",
        "          predicteds=[]\n",
        "          for i,(x, y) in enumerate(data):\n",
        "\n",
        "            x, y = x.clone().detach().to(device), y.clone().detach().to(device)\n",
        "            y = y.unsqueeze(-1)\n",
        "            x = x.permute(0,1, 4, 2, 3) # batch_size, num_frames, channels, height, width\n",
        "            x = x.float()\n",
        "\n",
        "            outputs = model(x)\n",
        "            predicted = np.array(outputs.cpu().numpy()>=0.5).astype(int)\n",
        "            actual.extend(list(y.cpu()))\n",
        "            predicteds.extend(list(predicted))\n",
        "        return np.array(actual).reshape(-1),np.array(predicteds).reshape(-1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJpfWYq50oVl",
        "outputId": "0b367d82-776b-4c55-d63b-af5571d28097",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fold 1/3: ----------------------------- \n",
            "Epoch 80, loss: 0.00002372              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97        46\n",
            "           1       0.95      0.90      0.93        21\n",
            "\n",
            "    accuracy                           0.96        67\n",
            "   macro avg       0.95      0.94      0.95        67\n",
            "weighted avg       0.96      0.96      0.95        67\n",
            "\n",
            "\n",
            "Fold 1, loss: 0.23743844032287598\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "fold 2/3: ----------------------------- \n",
            "Epoch 80, loss: 0.00000000              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        34\n",
            "           1       1.00      0.94      0.97        33\n",
            "\n",
            "    accuracy                           0.97        67\n",
            "   macro avg       0.97      0.97      0.97        67\n",
            "weighted avg       0.97      0.97      0.97        67\n",
            "\n",
            "\n",
            "Fold 2, loss: 0.1877880096435547\n",
            "-----------------------------------------------------------------------------------------------------\n",
            "fold 3/3: ----------------------------- \n",
            "Epoch 80, loss: 0.00000000              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        32\n",
            "           1       0.94      1.00      0.97        34\n",
            "\n",
            "    accuracy                           0.97        66\n",
            "   macro avg       0.97      0.97      0.97        66\n",
            "weighted avg       0.97      0.97      0.97        66\n",
            "\n",
            "\n",
            "Fold 3, loss: 1.5151515007019043\n",
            "-----------------------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "models_details=[]\n",
        "history = train_cross_validation(dataset,80 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYJ_xSukzMTh",
        "outputId": "525d3ff7-98cc-409e-c819-70ad84c0a8f6",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model number 0 ===================================\n",
            "classification:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97        46\n",
            "           1       0.95      0.90      0.93        21\n",
            "\n",
            "    accuracy                           0.96        67\n",
            "   macro avg       0.95      0.94      0.95        67\n",
            "weighted avg       0.96      0.96      0.95        67\n",
            "\n",
            "===================================================\n",
            "model number 1 ===================================\n",
            "classification:                precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      1.00      0.97        34\n",
            "           1       1.00      0.94      0.97        33\n",
            "\n",
            "    accuracy                           0.97        67\n",
            "   macro avg       0.97      0.97      0.97        67\n",
            "weighted avg       0.97      0.97      0.97        67\n",
            "\n",
            "===================================================\n",
            "model number 2 ===================================\n",
            "classification:                precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97        32\n",
            "           1       0.94      1.00      0.97        34\n",
            "\n",
            "    accuracy                           0.97        66\n",
            "   macro avg       0.97      0.97      0.97        66\n",
            "weighted avg       0.97      0.97      0.97        66\n",
            "\n",
            "===================================================\n"
          ]
        }
      ],
      "source": [
        "for i in range(3):\n",
        "  print(f\"model number {i} ===================================\")\n",
        "  # print(\"recall: \",history[i][\"recall\"])\n",
        "  # print(\"precision: \",history[i][\"precision\"])\n",
        "  # print(\"f1: \",history[i][\"f1\"])\n",
        "  # print(\"accuracy: \",history[i][\"accuracy\"])\n",
        "  print(\"classification: \",history[i][\"classification\"])\n",
        "  print(\"===================================================\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "fMGJOgcFpL7D",
        "outputId": "c3242453-33f5-4e04-c50d-57faf116d0d1",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(history[0][\"loss\"])\n",
        "plt.plot(history[1][\"loss\"])\n",
        "plt.plot(history[2][\"loss\"])\n",
        "plt.legend([\"model 1\",\"model 2\",\"model 3\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "mAvTvMEJrzjH",
        "trusted": true
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "-6x8oY-g0Hy5",
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 1909705,
          "sourceId": 3134515,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 2666698,
          "sourceId": 4570814,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30823,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
